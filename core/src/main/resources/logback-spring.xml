<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<include
		resource="org/springframework/boot/logging/logback/defaults.xml" />


	<springProperty scope="context" name="appName"
		source="spring.application.name" />

	<property name="CONSOLE_LOG_PATTERN"
		value="%d{yyyy-MM-dd HH:mm:ss.SSSZZ} [${appName:-}] %highlight(%-5level) [%t] %magenta([%X{user-id}/%X{session-id}/%X{request-id}]) %green([%c{32}.%M]) - %msg%n" />

	<!--<logger name="eu.sia.meda" level="DEBUG" /> -->


	<appender name="STDOUT"
		class="ch.qos.logback.core.ConsoleAppender">
		<encoder
			class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
			<pattern>${CONSOLE_LOG_PATTERN}</pattern>
		</encoder>
	</appender>

	<if condition='"TRUE".equals("${ENABLE_KAFKA_APPENDER}")'>
		<then>
			<!-- This is the kafkaAppender -->
			<appender name="kafkaAppender"
				class="com.github.danielwegener.logback.kafka.KafkaAppender">
				<encoder>
					<pattern>${CONSOLE_LOG_PATTERN}</pattern>
				</encoder>
				<topic>${KAFKA_APPENDER_TOPIC}</topic>
				<keyingStrategy
					class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
				<deliveryStrategy
					class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />

				<!-- Optional parameter to use a fixed partition -->
				<!-- <partition>0</partition> -->

				<!-- Optional parameter to include log timestamps into the kafka message -->
				<!-- <appendTimestamp>true</appendTimestamp> -->

				<!-- each <producerConfig> translates to regular kafka-client config 
					(format: key=value) -->
				<!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
				<!-- bootstrap.servers is the only mandatory producerConfig -->
				<producerConfig>bootstrap.servers=${KAFKA_APPENDER_BOOTSTRAP_SERVERS}
				</producerConfig>
				<!-- even if the producer buffer runs full, do not block the application but start to drop messages -->
				<producerConfig>block.on.buffer.full=${KAFKA_APPENDER_BLOCK_ON_BUFFER_FULL:-false}
				</producerConfig>
				<producerConfig>request.timeout.ms=${KAFKA_APPENDER_REQUEST_TIMEOUT_MS:-60000}
				</producerConfig>
				<producerConfig>security.protocol=${KAFKA_APPENDER_SECURITY_PROTOCOL:-SASL_SSL}
				</producerConfig>
				<producerConfig>sasl.mechanism=${KAFKA_APPENDER_SASL_MECHANISM:-PLAIN}
				</producerConfig>
				<producerConfig>sasl.jaas.config=${KAFKA_APPENDER_SASL_JAAS_CONFIG}
				</producerConfig>
				<producerConfig>client.id=${HOSTNAME}-${CONTEXT_NAME}-logback-meda</producerConfig>
				<!-- this is the fallback appender if kafka is not available. -->
				<appender-ref ref="STDOUT" />
			</appender>

			<appender name="ASYNC_KAFKA"
				class="ch.qos.logback.classic.AsyncAppender">
				<neverBlock>true</neverBlock>
				<discardingThreshold>0</discardingThreshold>
				<appender-ref ref="kafkaAppender" />
			</appender>

			<appender name="ASYNC_STDOUT"
				class="ch.qos.logback.classic.AsyncAppender">
				<neverBlock>true</neverBlock>
				<discardingThreshold>0</discardingThreshold>
				<appender-ref ref="STDOUT" />
			</appender>

			<root level="INFO"> 
				<appender-ref ref="ASYNC_STDOUT" />
				<appender-ref ref="kafkaAppender" />
			</root>
		</then> 
		<else>
			<root level="INFO">
				<appender-ref ref="STDOUT" />
			</root>
		</else>
	</if>
</configuration>
